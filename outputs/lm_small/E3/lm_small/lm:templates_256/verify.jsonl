{"run_id": "lm:templates_256", "challenge_family": "lm:templates", "n": 256, "tau": 0.05, "distances_mean": 0.010003950573849231, "distances_std": 0.004870668968896468, "T": 0.010003950573849231, "far_hat": 0.00390625, "frr_hat": 0.0, "confidence_radius": 0.0019208520867667793, "config_snapshot": {"experiment": "lm_small", "lm": {"reference": {"name": "TinyLlama/TinyLlama-1.1B", "seed": 0}, "variants": [{"type": "seed", "name": "TinyLlama/TinyLlama-1.1B", "seed": 1}, {"type": "lora", "name": "TinyLlama/TinyLlama-1.1B", "dataset": "small_sft", "steps": 500}, {"type": "quant", "name": "TinyLlama/TinyLlama-1.1B", "dtype": "int8"}, {"type": "distill", "teacher": "TinyLlama/TinyLlama-1.1B", "student": "TinyLlama/TinyLlama-1.1B", "budget": 20000}]}, "challenges": {"families": [{"family": "lm:templates", "n": 512, "params": {"templates": ["Add {a} + {b}.", "Spell the word '{w}' backwards.", "Translate '{t}' to French."], "slots": {"a": [1, 2, 3, 4, 5, 6, 7, 8, 9], "b": [1, 2, 3, 4, 5, 6, 7, 8, 9], "w": ["caterpillar", "monastery", "suspicious"], "t": ["hello world", "good morning", "see you soon"]}}}]}, "verification": {"canonicalize": {"lower": true, "strip_punct": true, "collapse_ws": true, "max_len": 128}, "distances": ["edit", "embed"], "tau_grid": [0.05, 0.1, 0.2, 0.3], "sequential": {"enabled": true, "alpha": 0.01, "beta": 0.01}}, "leakage": {"rhos": [0.0, 0.1, 0.25, 0.5]}}}
{"run_id": "lm:templates_256", "challenge_family": "lm:templates", "n": 256, "tau": 0.1, "distances_mean": 0.010003950573849231, "distances_std": 0.004870668968896468, "T": 0.010003950573849231, "far_hat": 0.50390625, "frr_hat": 0.0, "confidence_radius": 0.0019208520867667793, "config_snapshot": {"experiment": "lm_small", "lm": {"reference": {"name": "TinyLlama/TinyLlama-1.1B", "seed": 0}, "variants": [{"type": "seed", "name": "TinyLlama/TinyLlama-1.1B", "seed": 1}, {"type": "lora", "name": "TinyLlama/TinyLlama-1.1B", "dataset": "small_sft", "steps": 500}, {"type": "quant", "name": "TinyLlama/TinyLlama-1.1B", "dtype": "int8"}, {"type": "distill", "teacher": "TinyLlama/TinyLlama-1.1B", "student": "TinyLlama/TinyLlama-1.1B", "budget": 20000}]}, "challenges": {"families": [{"family": "lm:templates", "n": 512, "params": {"templates": ["Add {a} + {b}.", "Spell the word '{w}' backwards.", "Translate '{t}' to French."], "slots": {"a": [1, 2, 3, 4, 5, 6, 7, 8, 9], "b": [1, 2, 3, 4, 5, 6, 7, 8, 9], "w": ["caterpillar", "monastery", "suspicious"], "t": ["hello world", "good morning", "see you soon"]}}}]}, "verification": {"canonicalize": {"lower": true, "strip_punct": true, "collapse_ws": true, "max_len": 128}, "distances": ["edit", "embed"], "tau_grid": [0.05, 0.1, 0.2, 0.3], "sequential": {"enabled": true, "alpha": 0.01, "beta": 0.01}}, "leakage": {"rhos": [0.0, 0.1, 0.25, 0.5]}}}
{"run_id": "lm:templates_256", "challenge_family": "lm:templates", "n": 256, "tau": 0.2, "distances_mean": 0.010003950573849231, "distances_std": 0.004870668968896468, "T": 0.010003950573849231, "far_hat": 1.0, "frr_hat": 0.0, "confidence_radius": 0.0019208520867667793, "config_snapshot": {"experiment": "lm_small", "lm": {"reference": {"name": "TinyLlama/TinyLlama-1.1B", "seed": 0}, "variants": [{"type": "seed", "name": "TinyLlama/TinyLlama-1.1B", "seed": 1}, {"type": "lora", "name": "TinyLlama/TinyLlama-1.1B", "dataset": "small_sft", "steps": 500}, {"type": "quant", "name": "TinyLlama/TinyLlama-1.1B", "dtype": "int8"}, {"type": "distill", "teacher": "TinyLlama/TinyLlama-1.1B", "student": "TinyLlama/TinyLlama-1.1B", "budget": 20000}]}, "challenges": {"families": [{"family": "lm:templates", "n": 512, "params": {"templates": ["Add {a} + {b}.", "Spell the word '{w}' backwards.", "Translate '{t}' to French."], "slots": {"a": [1, 2, 3, 4, 5, 6, 7, 8, 9], "b": [1, 2, 3, 4, 5, 6, 7, 8, 9], "w": ["caterpillar", "monastery", "suspicious"], "t": ["hello world", "good morning", "see you soon"]}}}]}, "verification": {"canonicalize": {"lower": true, "strip_punct": true, "collapse_ws": true, "max_len": 128}, "distances": ["edit", "embed"], "tau_grid": [0.05, 0.1, 0.2, 0.3], "sequential": {"enabled": true, "alpha": 0.01, "beta": 0.01}}, "leakage": {"rhos": [0.0, 0.1, 0.25, 0.5]}}}
{"run_id": "lm:templates_256", "challenge_family": "lm:templates", "n": 256, "tau": 0.3, "distances_mean": 0.010003950573849231, "distances_std": 0.004870668968896468, "T": 0.010003950573849231, "far_hat": 1.0, "frr_hat": 0.0, "confidence_radius": 0.0019208520867667793, "config_snapshot": {"experiment": "lm_small", "lm": {"reference": {"name": "TinyLlama/TinyLlama-1.1B", "seed": 0}, "variants": [{"type": "seed", "name": "TinyLlama/TinyLlama-1.1B", "seed": 1}, {"type": "lora", "name": "TinyLlama/TinyLlama-1.1B", "dataset": "small_sft", "steps": 500}, {"type": "quant", "name": "TinyLlama/TinyLlama-1.1B", "dtype": "int8"}, {"type": "distill", "teacher": "TinyLlama/TinyLlama-1.1B", "student": "TinyLlama/TinyLlama-1.1B", "budget": 20000}]}, "challenges": {"families": [{"family": "lm:templates", "n": 512, "params": {"templates": ["Add {a} + {b}.", "Spell the word '{w}' backwards.", "Translate '{t}' to French."], "slots": {"a": [1, 2, 3, 4, 5, 6, 7, 8, 9], "b": [1, 2, 3, 4, 5, 6, 7, 8, 9], "w": ["caterpillar", "monastery", "suspicious"], "t": ["hello world", "good morning", "see you soon"]}}}]}, "verification": {"canonicalize": {"lower": true, "strip_punct": true, "collapse_ws": true, "max_len": 128}, "distances": ["edit", "embed"], "tau_grid": [0.05, 0.1, 0.2, 0.3], "sequential": {"enabled": true, "alpha": 0.01, "beta": 0.01}}, "leakage": {"rhos": [0.0, 0.1, 0.25, 0.5]}}}
