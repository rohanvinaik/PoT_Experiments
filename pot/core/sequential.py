from typing import Iterable, Callable, Tuple, Optional
import numpy as np
from math import log
from dataclasses import dataclass

@dataclass
class SPRTResult:
    """Result of SPRT sequential test"""
    decision: str  # 'accept_H0', 'accept_H1', or 'continue'
    log_likelihood_ratio: float
    n_samples: int
    distances: list
    
class SequentialTester:
    """
    Sequential Probability Ratio Test (SPRT) implementation
    Based on Algorithm 1 from the paper (Section 2.4)
    
    Tests:
    - H0: Models are equivalent (f ≡ f*)
    - H1: Models are different (f ≠ f*)
    """
    
    def __init__(self, alpha: float = 0.01, beta: float = 0.01, 
                 tau0: float = 0.01, tau1: float = 0.1):
        """
        Initialize SPRT with error rates
        
        Args:
            alpha: Type I error rate (False Accept Rate)
            beta: Type II error rate (False Reject Rate)
            tau0: Mean distance under H0 (same model)
            tau1: Mean distance under H1 (different model)
        """
        self.alpha = alpha
        self.beta = beta
        self.tau0 = tau0
        self.tau1 = tau1
        
        # SPRT thresholds from paper
        self.A = log((1 - beta) / alpha)  # Upper threshold (reject H0)
        self.B = log(beta / (1 - alpha))  # Lower threshold (accept H0)
        
        # State
        self.S = 0.0  # Log likelihood ratio sum
        self.n = 0    # Number of samples
        self.distances = []
        self._decided = False
        self._decision = None
    
    def update(self, distance: float) -> SPRTResult:
        """
        Update SPRT with new observation
        
        Args:
            distance: Observed distance between model outputs
            
        Returns:
            SPRTResult with current decision status
        """
        if self._decided:
            return SPRTResult(self._decision, self.S, self.n, self.distances)
        
        self.n += 1
        self.distances.append(distance)
        
        # Compute log likelihood ratio for this observation
        # Assuming exponential distribution for simplicity
        # L1(d) = likelihood under H1, L0(d) = likelihood under H0
        
        # Use normal approximation for distances
        sigma = 0.05  # Estimated standard deviation
        
        # Likelihood under H0 (mean = tau0)
        L0 = np.exp(-(distance - self.tau0)**2 / (2 * sigma**2))
        
        # Likelihood under H1 (mean = tau1)
        L1 = np.exp(-(distance - self.tau1)**2 / (2 * sigma**2))
        
        # Update log likelihood ratio sum
        if L0 > 0:
            self.S += log(L1 / L0)
        else:
            self.S += 10  # Large positive value if L0 is 0
        
        # Check stopping conditions
        if self.S <= self.B:
            self._decided = True
            self._decision = 'accept_H0'
        elif self.S >= self.A:
            self._decided = True
            self._decision = 'accept_H1'
        else:
            self._decision = 'continue'
        
        return SPRTResult(self._decision, self.S, self.n, self.distances)
    
    def decided(self) -> bool:
        """Check if test has reached a decision"""
        return self._decided
    
    def accept(self) -> bool:
        """Check if H0 was accepted (models are equivalent)"""
        return self._decision == 'accept_H0'
    
    def expected_sample_size(self, under_h0: bool = True) -> float:
        """
        Compute expected sample size (Theorem 2 from paper)
        
        Args:
            under_h0: Whether to compute E[N|H0] or E[N|H1]
            
        Returns:
            Expected number of samples needed
        """
        if under_h0:
            # Expected sample size under H0
            numerator = (1 - self.alpha) * log(self.beta / (1 - self.alpha))
            numerator += self.alpha * log((1 - self.beta) / self.alpha)
        else:
            # Expected sample size under H1
            numerator = self.beta * log(self.beta / (1 - self.alpha))
            numerator += (1 - self.beta) * log((1 - self.beta) / self.alpha)
        
        # KL divergence between distributions
        # Using normal approximation
        sigma = 0.05
        kl_divergence = (self.tau1 - self.tau0)**2 / (2 * sigma**2)
        
        if kl_divergence > 0:
            return abs(numerator / kl_divergence)
        else:
            return float('inf')

def sprt_test(stream: Iterable[float], mu0: float, mu1: float, 
              alpha: float, beta: float) -> Tuple[str, int]:
    """
    Sequential probability ratio test (legacy interface)
    
    Args:
        stream: Iterator of distance observations
        mu0: Mean under H0
        mu1: Mean under H1
        alpha: Type I error rate
        beta: Type II error rate
        
    Returns:
        (decision, n_samples) where decision is 'accept_H0' or 'accept_H1'
    """
    tester = SequentialTester(alpha, beta, mu0, mu1)
    
    for distance in stream:
        result = tester.update(distance)
        if result.decision != 'continue':
            return result.decision, result.n_samples
    
    # If stream ends without decision, make one based on current S
    if tester.S < 0:
        return 'accept_H0', tester.n
    else:
        return 'accept_H1', tester.n